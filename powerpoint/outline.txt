Kafka Essentials
----------------

Introduction
Core Concepts
Features
Kafka Streams
Kafka Connect
KSQL

Introduction
------------
Distributed commit log = basis
Kafka open source publish/subscribe:
- messaging system
- event hub
- streaming data platform

Messages (records):
- distributed
- stored durably
- processed in-order

Apache Kafka platform
---------------------
- Kafka Broker:
  - Producer/Consumer APIs
- Kafka Connect API
- Kafka Streams API

Confluent Kafka platform: https://docs.confluent.io/current/_images/confluentPlatform.png

History: developed at LinkedIn, spawned off Confluent by the originators

Why is Kafka FAST?
- queue (linear structure, O(1) reads/appends instead of trees (O(log(N))))
- no data copy
- binary data protocol (no serialization/deserialization)
- record batching
- compression of batches

Core Concepts
-------------
Records/Messages: unit of data. array of bytes. key/value
Topics: categorisatie van records (tabel/directory)
Partitions: deel ("shard") van topic. Topic heeft 1+ partities
            partitie heeft 0+ records
            partitie is een enkelvoudige, geordende APPEND-ONLY log
Replicas (ISR=In-Sync Replicas) - kopie van partitie tussen brokers
         een leader per partitie, 0+ volgers
         replicatiefactor = totaal aantal kopieën, fail-over mechanisme
         leader handelt schrijfacties af, volgers kopieren
Offset: unique oplopend volgnummer van record (in partitie), oplopend vanaf 0
        ieder bericht heeft een offset (uniek per partitie)
Kafka topics/partitions (diagram uit kafka documentatie)
Brokers - kafka server die de records beheert. Ontvangt berichten, kent offsets toe en commit berichten
Cluster - 1+ brokers, gecoordineerd door ZooKeeper
Producers - clients die records publiceren
 - acknowledgment.
Consumers - clients die records consumeren vanaf een topic.
Consumers kunnen samenwerken in een consumer group en de load verdelen, tot een limiet: iedere partitie wordt exclusief aan één consumer toebedeeld
De offset wordt per consumer, per partitie bijgehouden dor de broker vanaf Kafka 0.9 (wij gaan met 2.3 aan de slag) - daarvoor ZooKeeper

Retention - bepaalt hoe lang berichten worden bewaard (standaard 7 dagen), per topic:
 - instelbaar op tijd
 - instelbaar op grootte

Kafka Features
--------------
- duizenden clients
- clients onafhankelijk
- hoge throughput
- schaalbaar
- persistence and retention
- performance
- Pinterest (2018): > 2000 brokers (AWS), daily: >  800.000.000.000 messages,1.2 PB (10**15), peak 15.000.000 msg/sec
- LinkedIn:         > 1800 brokers,     , daily:  1.300.000.000.000, 330 TB (in)/1.2 PB (out)
Kafka Streams:
  Java client library for stream processing (query/process a continuous unbounded data stream)
  "Complex Event Processing"
  "Real time analytics"
  input/output are kafka Topics

Kafka Connect
- connectivity to/from Kafka (sources & sinks), > 90 connectors (licensed/open source)

Confluent KSQL
- open source streaming SQL engine for stream processing on kafka
- interactive SQL interface
- KSQL: query your streams without writing code
- No Java required
- Uses Kafka Streams internally
